# Introduction

Deep neural networks have become increasingly influential in many complex machine-learning tasks, including visual and speech recognition problems. 
Unfortunately, many neural networks are vulnerable to adversarial examples. 
An adversarial example for a neural classifier is the result of applying minor modifications to a correctly classified valid input such that the modified input is classified incorrectly. 
Certifiably robust classifiers offer the most rigorous solution to this problem and provably protect models against adversarial examplesâ€™ attacks. 
These classifiers are constructed by composing a standard classifier with a certified run-time defense.

In this repository, we show through experiments that even complete defenses are inherently over-cautious. 
We introduce a degradation attack and empirically demonstrate the efficacy of such attacks against state-of-the-art certifiable defenses.

# Experiment results


# Installation

1. Clone the repository and change into its root directory.

2. Install from source via
```
conda env create -f experimants/fpr/environment.yml
conda activate myenv
pip install -e .
```
# Run experiments

## Lowerbound experiments
In this experiments, we compute lower bounds on the efficacy of the degradation attacks using the smoothed projected gradient descent attack (SPGD) algorithm. File `experiments/dos/script_attack_kw.py` calculate the attack results on gloro model and file `experiments/dos/script_attack_rs.py` calculate the results on randomized smoothing model. 

## Upperbound experiments
In this experiments, we compute upper bounds on the efficacy of degradation attacks, i.e., upper bounds on the false positive rates. The experiment includes both gloro model and randomized smoothing model. In gloro, we train our own model (`trainGloro.py`) and calculate the certified radius (`printRadius.py`), to get the data and in randomized smoothing model, we use the data generated by randomized smoothing paper at `https://github.com/locuslab/smoothing/tree/master/data/certify`. For data analyzing and generate the plots shown on the paper, we use the file analyze.py.

### experiments/fpr/trainGloro.py
This file trains the gloro models. Hyperprameters for trainning and evaluating the model should be provided in the command line as following. 
```
python trainGloro.py --experiment='gloro' --superrobust='Y' --dataset="mnist" --architecture="minmax_cnn_2C2F" --epsilon=0.3 --epsilon_train=0.3 --epsilon_schedule='fixed' --loss='trades.0.1' --augmentation=None --epochs=500 --batch_size=128 --optimizer='adam' --lr=1e-3 --lr_schedule='decay_to_0.000001' --trades_schedule='linear,0.1,2.0'

python trainGloro.py --experiment='gloro' --superrobust='N' --dataset="mnist" --architecture="minmax_cnn_2C2F" --epsilon=0.3 --epsilon_train=0.3 --epsilon_schedule='fixed' --loss='trades.0.1' --augmentation=None --epochs=500 --batch_size=128 --optimizer='adam' --lr=1e-3 --lr_schedule='decay_to_0.000001' --trades_schedule='linear,0.1,2.0'

python trainGloro.py --experiment='gloro' --superrobust='Y' --dataset="mnist" --architecture="minmax_cnn_4C3F" --epsilon=1.58 --epsilon_train=1.74 --epsilon_schedule='logarithmic' --loss='trades.1.5' --augmentation=None --epochs=500 --batch_size=128 --optimizer='adam' --lr=1e-3 --lr_schedule='decay_to_0.000005' --trades_schedule='fixed'

python trainGloro.py --experiment='gloro' --superrobust='N' --dataset="mnist" --architecture="minmax_cnn_4C3F" --epsilon=1.58 --epsilon_train=1.74 --epsilon_schedule='logarithmic' --loss='trades.1.5' --augmentation=None --epochs=500 --batch_size=128 --optimizer='adam' --lr=1e-3 --lr_schedule='decay_to_0.000005' --trades_schedule='fixed'

python trainGloro.py --experiment='gloro' --superrobust='Y' --dataset="cifar10" --architecture="minmax_cnn_6C2F" --epsilon=36/255 --epsilon_train=36/255 --epsilon_schedule='logarithmic' --loss='trades.1.2' --augmentation='cifar' --epochs=800 --batch_size=512 --optimizer='adam' --lr=1e-3 --lr_schedule='decay_to_0.000001' --trades_schedule='fixed'

python trainGloro.py --experiment='gloro' --superrobust='N' --dataset="cifar10" --architecture="minmax_cnn_6C2F" --epsilon=36/255 --epsilon_train=36/255 --epsilon_schedule='logarithmic' --loss='trades.1.2' --augmentation='cifar' --epochs=800 --batch_size=512 --optimizer='adam' --lr=1e-3 --lr_schedule='decay_to_0.000001' --trades_schedule='fixed'
```

### experiments/fpr/printRadius.py
Print out the correct label, model predicted label, certified robust radius and correctness for each point of test data in the given dataset, using the given gloro models. The input model could either be the model generated by file trainGloro.py or model in directory models. An example command to run this file is shown as following.

```
python experiments/fpr/printRadius.py --dataset="cifar10" --batch_size=128 --model="./models/cifar10_0.14_N.gloronet"
```


### experiments/fpr/analyze.py
Analyze the data of certified radius etc. and generate plots for visualization. The data could from both gloro model (by file `printRadius.py`) and randomized smoothing model. The generated data for both models are stored in the file `experimants/fpr/data/`

```
python experiments/fpr/analyze.py --dataFile=experimants/fpr/
```
